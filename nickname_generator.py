#!/usr/bin/env python3
"""
Nickname Generator GUI (customtkinter).

- Matches main/auditor app styling (no blue window frame)
- Lets user select an input names file (txt/csv), choose output CSV, and options
- Runs generation in a background thread and streams logs to a textbox
-- Self-contained: includes nickname generation and file handling logic inline (no local project imports)
"""

import os
import sys
import threading
import tkinter as tk
from tkinter import filedialog, messagebox
from tkinter import font as tkfont
import re
import csv
from typing import List, Set, Dict, Optional, Tuple
from datetime import datetime
import argparse

# Optional native splash support (PyInstaller)
try:
    import pyi_splash as _pyi_splash  # type: ignore
except Exception:
    _pyi_splash = None  # type: ignore

try:
    import pandas as pd  # type: ignore
except Exception:
    pd = None  # type: ignore
import customtkinter as ctk

try:
    import winsound  # type: ignore
except Exception:
    winsound = None  # type: ignore

 
# --- App constants (self-contained) ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# No custom theme applied; using CTk defaults to match main/auditor apps

# --- Embedded nickname generator logic (no local imports) ---
class NicknameGenerator:
    """Main class for generating nicknames from formal names."""
    def __init__(self, enable_phonetic: bool = True, overrides_map: Optional[Dict[str, List[Dict[str, str]]]] = None):
        self.enable_phonetic = enable_phonetic
        # formal (lowercased, space-normalized) -> list of dict entries with metadata
        # each entry: { 'nickname': str, 'variant_type': str, 'confidence': str, 'notes': str }
        self.overrides_map: Dict[str, List[Dict[str, str]]] = overrides_map or {}
        self.common_nicknames = {
            'alexander': ['alex', 'xander', 'lex'],
            'alexandra': ['alex', 'alexa', 'sandra'],
            'alexis': ['alex', 'lex'],
            'robert': ['rob'],
            'roberto': ['robert', 'bert', 'berto'],
            'joseph': ['joey', 'joe'],
            'josephine': ['josie'],
            'joshua': ['josh'],
            'jonathan': ['jon', 'john'],
            'john': ['jon', 'johnny'],
            'alfred': ['alfie', 'fred'],
            'alfredo': ['alfie', 'fred'],
            'frederick': ['fred', 'freddie'],
            'christopher': ['chris', 'topher'],
            'christian': ['chris'],
            'rizaldy': ['rizal', 'zaldy'],
            'jeanette': ['jean', 'nette'],
            'donalyn': ['dona', 'lyn'],
            'leonilo': ['leo', 'nilo'],
            'allan': ['al', 'all'],  # per user conservative samples
            'angelo': ['gelo'],
            'pamela': ['pam'],
            'teresa': ['tess'],
            'catherine': ['cathy', 'kate'],
        }

        self.well_known_nicknames = {
            'Abigail': [('Abby', 'High', 'Common variant')],
            'Agustin': [('Gus', 'Medium', 'Common variant')],
            'Alberto': [('Albert', 'High', 'Common variant')],
            'Alejandro': [('Alex', 'High', 'Common variant')],
            'Alfredo': [('Freddie', 'High', 'Common variant'), ('Fredo', 'High', 'Common variant')],
            'Angelica': [('Angel', 'High', 'Common variant')],
            'Antonio': [('Tony', 'High', 'Common variant')],
            'Benjamin': [('Benjie', 'High', 'Common PH variant')],
            'Bernadette': [('Berna', 'High', 'Common variant')],
            'Bernardo': [('Bernie', 'High', 'Common variant')],
            'Carmela': [('Mel', 'High', 'Common variant')],
            'Catherine': [('Cathy', 'High', 'Common variant'), ('Kate', 'High', 'Common variant')],
            'Charles': [('Charlie', 'High', 'Common variant')],
            'Christopher': [('Topher', 'High', 'Common PH variant')],
            'Concepcion': [('Connie', 'High', 'Common PH variant'), ('Concha', 'Medium', 'Older variant')],
            'Consolacion': [('Connie', 'High', 'Common PH variant'), ('Sol', 'High', 'Common variant')],
            'Corazon': [('Cora', 'High', 'Common PH variant')],
            'Daniel': [('Dan', 'High', 'Common variant')],
            'David': [('Dave', 'High', 'Common variant')],
            'Dolores': [('Lola', 'Medium', 'Older variant'), ('Lorie', 'High', 'Common variant')],
            'Eduardo': [('Eddie', 'High', 'Common variant'), ('Eddieboy', 'High', 'Common PH variant')],
            'Eleanor': [('Leny', 'High', 'Common PH variant'), ('Nora', 'High', 'Common variant')],
            'Elizabeth': [('Beth', 'High', 'Common variant'), ('Liz', 'High', 'Common variant')],
            'Enrique': [('Ricky', 'High', 'Common PH variant'), ('Iking', 'Medium', 'Older PH variant')],
            'Ernesto': [('Ernie', 'High', 'Common variant')],
            'Esperanza': [('Ansa', 'Medium', 'Common PH variant')],
            'Evangeline': [('Vangie', 'High', 'Common PH variant')],
            'Felipe': [('Philip', 'High', 'Common variant')],
            'Ferdinand': [('Ferdie', 'High', 'Common PH variant')],
            'Francisco': [('Kiko', 'High', 'Common PH variant'), ('Frank', 'High', 'Common variant')],
            'Gabriel': [('Gabby', 'High', 'Common variant')],
            'Gerardo': [('Gerard', 'High', 'Common variant')],
            'Gloria': [('Glo', 'Medium', 'Common variant')],
            'Guillermo': [('Gimo', 'High', 'Common PH variant'), ('Willie', 'High', 'Common variant')],
            'Herminia': [('Hermie', 'High', 'Common PH variant')],
            'Ignacio': [('Nacho', 'High', 'Spanish-derived variant'), ('Iggy', 'High', 'Common variant')],
            'Isabel': [('Bel', 'High', 'Common variant')],
            'Isidro': [('Sid', 'High', 'Common variant')],
            'Javier': [('Javy', 'High', 'Common variant')],
            'Jesus': [('Jess', 'High', 'Common PH variant')],
            'Joaquin': [('Kino', 'Medium', 'Common variant')],
            'Jose': [('Pepe', 'High', 'Historical PH variant'), ('Joey', 'High', 'Common variant')],
            'Josefina': [('Josie', 'High', 'Common variant'), ('Jophen', 'Medium', 'PH variant')],
            'Josephine': [('Josie', 'High', 'Common variant')],
            'Leticia': [('Letty', 'High', 'Common variant')],
            'Lorenzo': [('Enzo', 'High', 'Common PH core nickname')],
            'Manuel': [('Manny', 'High', 'Common variant'), ('Manolo', 'High', 'Common variant')],
            'Margarita': [('Marga', 'High', 'Common variant'), ('Rita', 'High', 'Common variant')],
            'Mercedes': [('Mercy', 'High', 'Common variant')],
            'Michael': [('Mike', 'High', 'Common variant')],
            'Miguel': [('Mike', 'High', 'Common variant')],
            'Nathaniel': [('Nathan', 'High', 'Common variant')],
            'Nicolas': [('Nico', 'High', 'Common variant')],
            'Patricio': [('Pat', 'High', 'Common variant')],
            'Prudencio': [('Dencio', 'High', 'Common PH variant')],
            'Rafael': [('Raffy', 'High', 'Common PH variant')],
            'Ramon': [('Mon', 'High', 'Common variant')],
            'Remedios': [('Remy', 'High', 'Common variant')],
            'Renato': [('Rene', 'High', 'Common variant')],
            'Ricardo': [('Cardo', 'High', 'Common PH variant'), ('Ricky', 'High', 'Common variant')],
            'Roberto': [('Bobby', 'High', 'Common PH variant'), ('Bert', 'High', 'Common variant')],
            'Roderick': [('Eric', 'High', 'Common variant')],
            'Rogelio': [('Roger', 'High', 'Common variant')],
            'Rosario': [('Charo', 'High', 'Common PH variant')],
            'Salvador': [('Sal', 'High', 'Common variant'), ('Badong', 'Medium', 'Older PH variant')],
            'Santiago': [('Tiago', 'High', 'Common PH variant')],
            'Teresa': [('Tess', 'High', 'Common variant'), ('Tessa', 'High', 'Common variant')],
            'Teresita': [('Tess', 'High', 'Common variant'), ('Tessie', 'High', 'Common variant')],
            'Victoria': [('Vicky', 'High', 'Common variant')],
            'Virgilio': [('Ver', 'High', 'Common variant')],
            'Virginia': [('Virgie', 'High', 'Common variant')],
            'William': [('Willie', 'High', 'Common variant'), ('Bill', 'Medium', 'Western variant')],
            'Yolanda': [('Yoly', 'High', 'Common PH variant')],
        }

        self.core_nicknames = {
            'Angelica': [('Geli', 'High', 'Common core nickname')],
            'Bernadette': [('Det', 'Medium', 'Common core nickname')],
            'Carmela': [('Mel', 'High', 'Common core nickname')],
            'Christina': [('Tin', 'High', 'Common PH core nickname')],
            'Christine': [('Tin', 'High', 'Common PH core nickname')],
            'Eleanor': [('Lean', 'Medium', 'Common core nickname')],
            'Gregorio': [('Gorio', 'High', 'Common PH core nickname')],
            'Isidro': [('Sid', 'High', 'Common core nickname')],
        }
    def generate_prefix_nicknames(self, token: str) -> Set[str]:
        """Conservative prefixes: 3-letter prefix, plus select 2-letter forms like Al/Jo/El."""
        n = token.lower()
        out: Set[str] = set()
        if len(n) >= 3:
            out.add((n[:3]).capitalize())
        # Selected 2-letter forms seen in real usage
        two_letter = {"al", "jo", "el"}
        if len(n) >= 2 and n[:2] in two_letter:
            out.add((n[:2]).capitalize())
        return out

    def generate_conservative_parts(self, token: str) -> Set[str]:
        """Extract a conservative set of substrings commonly used as nicknames.

        Rules:
        - Known suffix nicknames: bert, berto, renzo, nald, lito, lyn/lynn, mel
        - Common cores: ric, vic, greg, leo
        - Whole-word when multi-part names are given is handled elsewhere
        """
        n = token.lower()
        out: Set[str] = set()
        def cap(x: str) -> str:
            return x[:1].upper() + x[1:].lower() if x else x

        # Suffix-based
        for suf in ("berto", "bert", "renzo", "nald", "lito", "mel"):
            if n.endswith(suf):
                out.add(cap(suf))
        # Special: -lyn / -lynn
        if n.endswith("lyn") or n.endswith("lynn"):
            out.add("Lyn")
            base = n[:-3] if n.endswith("lyn") else n[:-4]
            if len(base) >= 4:
                out.add(cap(base))
        # Common cores/prefixes
        if n.startswith("leo"):
            out.add("Leo")
        if n.startswith("vic"):
            out.add("Vic")
        if n.startswith("rom"):
            out.add("Rom")
        if n.startswith("mar"):
            out.add("Mar")
        if n.startswith("noel"):
            out.add("Noel")
        if "ric" in n:
            out.add("Ric")
        if "greg" in n:
            out.add("Greg")
        if n.startswith("cel"):
            out.add("Cel")
        if n.startswith("eli"):
            out.add("Eli")
        if "ben" in n:
            out.add("Ben")
        if n.startswith("sha"):
            out.add("Sha")
        # Specific: Richard -> Chard
        if n.endswith("chard"):
            out.add("Chard")
        # Specific: Rowena -> Wena
        if n.startswith("rowena"):
            out.add("Wena")
        return out
    def generate_common_nicknames(self, name: str) -> Set[str]:
        n = name.lower()
        out: Set[str] = set()
        if n in self.common_nicknames:
            out.update([x.capitalize() for x in self.common_nicknames[n]])
        return out
    def generate_phonetic_nicknames(self, token: str) -> Set[str]:
        """Only allow conservative 'h'-pair changes: ch->k, th->t, ph->p, jh->j."""
        n = token.lower()
        out: Set[str] = set()
        modified = n
        phonetic_subs = {'ch': 'k', 'th': 't', 'ph': 'p', 'jh': 'j'}
        for o, r in phonetic_subs.items():
            if o in modified:
                modified = modified.replace(o, r)
        if modified != n and len(modified) >= 2:
            out.add(modified.capitalize())
        return out
    def has_override_for(self, name: str) -> bool:
        """Return True if the full name exists in the overrides map (raw or normalized)."""
        try:
            parts = [p for p in re.split(r"\s+", name.strip()) if p]
            raw_key = " ".join(parts).lower()
            # Build normalized key similar to generation normalization (Ma. -> Maria)
            normalized: List[str] = []
            for p in parts:
                pl = p.lower().strip('.')
                if pl in {"ma", "ma."} or p.lower() == "ma.":
                    normalized.append("Maria")
                else:
                    normalized.append(p)
            norm_key = " ".join(normalized).lower()
            return (raw_key in self.overrides_map) or (norm_key in self.overrides_map)
        except Exception:
            return False
    def generate_all_nicknames(self, name: str) -> Set[str]:
        """Conservative nickname generation.

        - Split multi-part names into tokens; each token can yield nicknames.
        - Expand 'Ma.' token to 'Maria'.
        - If a single token starts with 'maria' and continues (e.g., 'mariafe'), split into 'Maria' + remainder.
        - For two-word names where the second is 'Ann/Anne/An', also create first+'n' (e.g., 'Lovely Ann' -> 'Lovelyn').
        - If the name has two or more words: only use whole-word tokens (plus the special cases above). Do not derive nicknames from prefixes/cores for each part.
        - If the name is a single word: apply per-name overrides if available; otherwise apply conservative parts (and optional phonetics) and select 3-letter prefix.
        """
        out: Set[str] = set()
        name_norm = re.sub(r"\s+", " ", name.strip()).lower()

        # 1. Overrides have highest priority
        if self.has_override_for(name):
            # In CLI mode, overrides are handled separately. In GUI, this applies them.
            # For now, this method just signals that an override exists.
            # The actual nickname data is added by the caller.
            pass

        # Check new knowledge bases first (case-insensitive key match)
        name_cap = name.strip().capitalize()
        # Find a matching key case-insensitively
        for formal_key, nick_list in self.well_known_nicknames.items():
            if formal_key.lower() == name.strip().lower():
                out.update([nick_info[0] for nick_info in nick_list])
                break
        for formal_key, nick_list in self.core_nicknames.items():
            if formal_key.lower() == name.strip().lower():
                out.update([nick_info[0] for nick_info in nick_list])
                break

        tokens = [p for p in re.split(r"\s+", name.strip()) if p]

        # Multi-word special cases
        if len(tokens) >= 2:
            # Lovely + Ann/Anne/An -> Lovelyn
            try:
                first, second = tokens[0], tokens[1]
                if second.lower() in {"ann", "anne", "an"}:
                    nick = (first + "n").capitalize()
                    out.add(nick)
            except Exception:
                pass

            # For multi-word, only use whole tokens as nicknames (conservative mode)
            for tok in tokens:
                # Expand 'Ma.' -> 'Maria'
                if tok.lower().strip('.') in {"ma", "ma."}:
                    out.add("Maria")
                else:
                    # Add the token itself if it's a valid nickname candidate
                    clean_tok = re.sub(r'[^A-Za-z]', '', tok)
                    if len(clean_tok) >= 2:
                        out.add(clean_tok.capitalize())
            # For multi-word names, we don't apply further single-word logic, just return what we have.
            # The final filtering at the end will still apply.

        # Single-word name logic
        if len(tokens) <= 1:
            tok_clean = re.sub(r'[^A-Za-z]', '', name)
            n = tok_clean.lower()

            # Expand 'Ma.' -> 'Maria'
            if n.startswith("ma.") or n == 'ma':
                out.add("Maria")

            # Maria-prefixed names (e.g., Mariafe -> Maria, Fe)
            if n.startswith("maria") and len(n) > 5:
                out.add("Maria")
                rem = n[5:]
                if len(rem) >= 2:
                    out.add(rem.capitalize())

            # 3-letter prefix
            if len(tok_clean) >= 3:
                out.add(tok_clean[:3].capitalize())

            # Common nicknames (from original simple list)
            if n in self.common_nicknames:
                out.update([x.capitalize() for x in self.common_nicknames[n]])

            # Conservative parts
            out.update(self.generate_conservative_parts(tok_clean))

            # Phonetic whole-token variant (restricted h-pairs)
            if self.enable_phonetic:
                out.update(self.generate_phonetic_nicknames(tok_clean))

        # Final filtering
        filtered: Set[str] = set()
        base = name.lower()
        for nick in out:
            n_str = nick.strip()
            if not n_str:
                continue
            if n_str.lower() == base:
                continue
            if len(n_str) < 2:
                continue
            if not n_str.isalpha():
                continue
            filtered.add(n_str)
        return filtered

class FileHandler:
    @staticmethod
    def read_names_and_optional_gender(file_path: str) -> Tuple[List[str], Dict[str, str]]:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Input file not found: {file_path}")
        ext = os.path.splitext(file_path)[1].lower()
        names: List[str] = []
        gender_map: Dict[str, str] = {}
        try:
            if ext == '.csv':
                name_candidates = ['name', 'first_name', 'firstname', 'names', 'formalname', 'formal_name', 'formal', 'formal name']
                if pd is not None:
                    df = pd.read_csv(file_path)
                    lower_cols = [c.lower() for c in df.columns]
                    name_col = None
                    for key in name_candidates:
                        if key in lower_cols:
                            name_col = df.columns[lower_cols.index(key)]
                            break
                    if name_col is None:
                        name_col = df.columns[0]
                    names = df[name_col].dropna().astype(str).tolist()
                    # Optional Gender column
                    gender_col = None
                    gender_candidates = ['gender', 'sex']
                    for g_key in gender_candidates:
                        if g_key in lower_cols:
                            gender_col = df.columns[lower_cols.index(g_key)]
                            break
                    if gender_col:
                        agg: Dict[str, Set[str]] = {}
                        for _, row in df.iterrows():
                            nm = str(row[name_col]).strip()
                            gd = str(row[gender_col]).strip().lower()
                            if not nm or not gd:
                                continue
                            if gd not in {'male', 'female', 'unisex'}:
                                continue
                            # Capitalize gender to match AI format
                            gd = gd.capitalize()
                            key = nm.lower()
                            agg.setdefault(key, set()).add(gd)
                        for key, genders in agg.items():
                            if 'Unisex' in genders or (('Male' in genders) and ('Female' in genders)):
                                gender_map[key] = 'Unisex'
                            elif 'Male' in genders:
                                gender_map[key] = 'Male'
                            elif 'Female' in genders:
                                gender_map[key] = 'Female'
                            else:
                                gender_map[key] = 'unisex'
                else:
                    # Fallback CSV parsing without pandas
                    with open(file_path, 'r', newline='', encoding='utf-8-sig') as f:
                        reader = csv.DictReader(f)
                        # If no header, treat as single column
                        if reader.fieldnames is None:
                            f.seek(0)
                            names = [row.strip() for row in f if row.strip()]
                        else:
                            lower_map = {c.lower(): c for c in reader.fieldnames}
                            name_col = None
                            for key in name_candidates:
                                if key in lower_map:
                                    name_col = lower_map[key]
                                    break
                            if name_col is None:
                                name_col = reader.fieldnames[0]
                            gender_header = None
                            for g_key in ['gender', 'sex']:
                                if g_key in lower_map:
                                    gender_header = lower_map[g_key]
                                    break
                            gender_agg: Dict[str, Set[str]] = {}
                            for row in reader:
                                nm = str(row.get(name_col, '')).strip()
                                if nm:
                                    names.append(nm)
                                if gender_header:
                                    gd = str(row.get(gender_header, '')).strip().lower()
                                    if gd in {'male', 'female', 'unisex'} and nm:
                                        gender_agg.setdefault(nm.lower(), set()).add(gd.capitalize())
                            for key, genders in gender_agg.items():
                                if 'Unisex' in genders or (('Male' in genders) and ('Female' in genders)):
                                    gender_map[key] = 'Unisex'
                                elif 'Male' in genders:
                                    gender_map[key] = 'Male'
                                elif 'Female' in genders:
                                    gender_map[key] = 'Female'
                                else:
                                    gender_map[key] = 'Unisex'
            else:
                with open(file_path, 'r', encoding='utf-8') as f:
                    names = [line.strip() for line in f if line.strip()]
            if not names:
                raise ValueError(f"No names found in file: {file_path}")
            return names, gender_map
        except Exception as e:
            raise ValueError(f"Error reading file {file_path}: {str(e)}")
    @staticmethod
    def read_overrides_csv(file_path: str) -> Dict[str, List[Dict[str, str]]]:
        """Load curated overrides CSV with full metadata (no filtering).

        Returns mapping: formal(lower, space-normalized) -> list of entries
        entry keys: 'nickname', 'variant_type', 'confidence', 'notes'
        Column detection is flexible and case-insensitive. If 'Notes' is
        absent, it will be an empty string.
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Overrides CSV not found: {file_path}")
        mapping: Dict[str, List[Dict[str, str]]] = {}
        try:
            if pd is not None:
                df = pd.read_csv(file_path)
                lower_cols = {c.lower(): c for c in df.columns}
                # Columns
                def get_col(cands: List[str]) -> Optional[str]:
                    for k in cands:
                        if k in lower_cols:
                            return lower_cols[k]
                    return None
                formal_col = get_col(['formalname', 'formal', 'formal_name', 'formal name', 'name']) or (df.columns[0] if len(df.columns) >= 1 else None)
                nickname_col = get_col(['nickname', 'nick', 'alias', 'variant', 'nickname/alias']) or (df.columns[1] if len(df.columns) >= 2 else None)
                conf_col = get_col(['confidence', 'confidence_level'])
                vtype_col = get_col(['varianttype', 'variant_type', 'type', 'category'])
                notes_col = get_col(['notes', 'comment', 'remarks'])
                if formal_col is None or nickname_col is None:
                    raise ValueError("Could not detect Formal/Nickname columns in overrides CSV")
                for _, row in df.iterrows():
                    formal = str(row.get(formal_col, '')).strip()
                    nick = str(row.get(nickname_col, '')).strip()
                    if not formal or not nick:
                        continue
                    key = re.sub(r"\s+", " ", formal).strip().lower()
                    nv = nick[:1].upper() + nick[1:].lower()
                    if not re.fullmatch(r"[A-Za-z][A-Za-z\-]*", nv) or len(nv) < 2:
                        continue
                    entry = {
                        'nickname': nv,
                        'variant_type': str(row.get(vtype_col, '')).strip() if vtype_col else '',
                        'confidence': str(row.get(conf_col, '')).strip() if conf_col else '',
                        'notes': str(row.get(notes_col, '')).strip() if notes_col else '',
                    }
                    mapping.setdefault(key, []).append(entry)
            else:
                with open(file_path, 'r', newline='', encoding='utf-8-sig') as f:
                    reader = csv.DictReader(f)
                    if reader.fieldnames is None:
                        # Expect two columns: Formal, Nickname (no header)
                        f.seek(0)
                        simple_reader = csv.reader(f)
                        for row in simple_reader:
                            if len(row) < 2:
                                continue
                            formal = str(row[0]).strip()
                            nick = str(row[1]).strip()
                            if not formal or not nick:
                                continue
                            key = re.sub(r"\s+", " ", formal).strip().lower()
                            nv = nick[:1].upper() + nick[1:].lower()
                            if not re.fullmatch(r"[A-Za-z][A-Za-z\-]*", nv) or len(nv) < 2:
                                continue
                            entry = {
                                'nickname': nv,
                                'variant_type': '',
                                'confidence': '',
                                'notes': '',
                            }
                            mapping.setdefault(key, []).append(entry)
                    else:
                        lower_map = {c.lower(): c for c in reader.fieldnames}
                        def get_hdr(cands: List[str]) -> Optional[str]:
                            for k in cands:
                                if k in lower_map:
                                    return lower_map[k]
                            return None
                        formal_hdr = get_hdr(['formalname', 'formal', 'formal_name', 'formal name', 'name'])
                        nickname_hdr = get_hdr(['nickname', 'nick', 'alias', 'variant', 'nickname/alias'])
                        conf_hdr = get_hdr(['confidence', 'confidence_level'])
                        vtype_hdr = get_hdr(['varianttype', 'variant_type', 'type', 'category'])
                        notes_hdr = get_hdr(['notes', 'comment', 'remarks'])
                        if formal_hdr is None or nickname_hdr is None:
                            headers = reader.fieldnames
                            if headers and len(headers) >= 2:
                                formal_hdr = headers[0]
                                nickname_hdr = headers[1]
                            else:
                                raise ValueError("Could not detect Formal/Nickname columns in overrides CSV")
                        for row in reader:
                            formal = str(row.get(formal_hdr, '')).strip()
                            nick = str(row.get(nickname_hdr, '')).strip()
                            if not formal or not nick:
                                continue
                            key = re.sub(r"\s+", " ", formal).strip().lower()
                            nv = nick[:1].upper() + nick[1:].lower()
                            if not re.fullmatch(r"[A-Za-z][A-Za-z\-]*", nv) or len(nv) < 2:
                                continue
                            entry = {
                                'nickname': nv,
                                'variant_type': str(row.get(vtype_hdr, '')).strip() if vtype_hdr else '',
                                'confidence': str(row.get(conf_hdr, '')).strip() if conf_hdr else '',
                                'notes': str(row.get(notes_hdr, '')).strip() if notes_hdr else '',
                            }
                            mapping.setdefault(key, []).append(entry)
            return mapping
        except Exception as e:
            raise ValueError(f"Error reading overrides CSV {file_path}: {str(e)}")
    @staticmethod
    def next_output_path_for_input(input_path: str) -> str:
        """Return next available output CSV path in the same folder as input.

        Pattern: <source_base>_generated_nickname_<n>.csv, where n starts at 1
        and increments until a non-existing filename is found.
        """
        try:
            folder = os.path.dirname(input_path) or SCRIPT_DIR
            base = os.path.splitext(os.path.basename(input_path))[0]
            n = 1
            while True:
                candidate = os.path.join(folder, f"{base}_generated_nickname_{n}.csv")
                if not os.path.exists(candidate):
                    return candidate
                n += 1
        except Exception:
            # Fallback to script directory if anything unexpected happens
            return os.path.join(SCRIPT_DIR, "generated_nickname_1.csv")
    @staticmethod
    def write_nicknames_to_csv(nicknames_data: List[Dict[str, str]], output_path: str):
        try:
            ai_cols = ['FormalName', 'Sex', 'Nickname', 'VariantType', 'Confidence', 'Notes']
            if pd is not None:
                df = pd.DataFrame(nicknames_data)
                # Remove Source column if present
                drop_cols = [c for c in df.columns if c not in ai_cols]
                if drop_cols:
                    df = df.drop(columns=drop_cols)
                # Enforce AI CSV column order
                if all(c in df.columns for c in ai_cols):
                    df = df[ai_cols]
                df.to_csv(output_path, index=False)
                return
            # Fallback: csv module
            # Collect fieldnames across all rows
            field_set: Set[str] = set()
            for row in nicknames_data:
                field_set.update(row.keys())
            # Prefer AI schema if present
            if all(k in field_set for k in ai_cols):
                fieldnames = ai_cols[:]
            else:
                fieldnames = sorted(field_set)
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                writer.writeheader()
                for row in nicknames_data:
                    # Remove Source if present
                    if 'Source' in row:
                        row = {k: v for k, v in row.items() if k != 'Source'}
                    writer.writerow(row)
        except Exception as e:
            raise ValueError(f"Error writing to CSV file {output_path}: {str(e)}")
    @staticmethod
    def gender_match(g1: Optional[str], g2: Optional[str]) -> str:
        def norm(g: Optional[str]) -> Optional[str]:
            if not g:
                return None
            g = g.lower()
            return g if g in {'male', 'female', 'unisex'} else None
        a = norm(g1)
        b = norm(g2)
        if a is None and b is None:
            return 'unknown'
        if a == 'unisex' or b == 'unisex':
            return 'match'
        if a is None or b is None:
            return 'unknown'
        return 'match' if a == b else 'mismatch'


class NicknameThemedGUI(ctk.CTk):
    def __init__(self):
        super().__init__()
        ctk.set_appearance_mode("System")
        self.geometry("760x560")
        self.resizable(False, False)

        # Use default CTk styling (no custom blue background)
        self.title("Nickname Generator")
        
        # Set window icon
        try:
            logo_path = os.path.join(SCRIPT_DIR, "logo.ico")
            self.iconbitmap(logo_path)
        except Exception as e:
            print(f"Could not load window icon: {e}")

        # Tk variables
        self.input_path = tk.StringVar()
        # Fonts
        self._mono_font = self._get_mono_font()

        # State for post-generation actions
        self.last_output_path: Optional[str] = None
        self.open_button: Optional[ctk.CTkButton] = None

        self._build_ui()
        # Center on screen after layout is built
        self._center_on_screen()
        # Close native splash if running under PyInstaller
        try:
            if _pyi_splash:
                _pyi_splash.close()
        except Exception:
            pass

    # No custom bg helper needed

    def _card(self, parent):
        card = ctk.CTkFrame(parent)
        card.pack(fill=ctk.BOTH, expand=False, padx=16, pady=12)
        return card

    def _build_ui(self):
        # Header
        header = ctk.CTkFrame(self, height=64)
        header.pack(fill=ctk.X, padx=0, pady=(0, 8))
        title = ctk.CTkLabel(header, text="Nickname Generator", font=("Segoe UI", 20, "bold"))
        title.pack(side=ctk.LEFT, padx=16, pady=12)

        # Body
        body = ctk.CTkFrame(self)
        body.pack(fill=ctk.BOTH, expand=True, padx=8, pady=(0, 8))

        # File selector area (clean, modern)
        card = self._card(body)
        ctk.CTkLabel(card, text="Select Raw Names CSV (with optional Gender column)", font=("Segoe UI", 14, "bold")).grid(row=0, column=0, sticky="w", padx=8, pady=(16, 4))
        ent_in = ctk.CTkEntry(card, textvariable=self.input_path, width=520, font=("Segoe UI", 12))
        ent_in.grid(row=1, column=0, sticky="w", padx=8, pady=4)
        ctk.CTkButton(card, text="Browse...", command=self._browse_input, width=100).grid(row=1, column=1, sticky="w", padx=8, pady=4)
        ctk.CTkLabel(card, text="The app will automatically detect and use a 'Gender' column if present.", font=("Segoe UI", 10)).grid(row=2, column=0, columnspan=2, sticky="w", padx=8, pady=(0, 12))

        # Output location preview (auto-generated)
        self.output_preview = ctk.CTkLabel(card, text="Output will be saved as: ", font=("Segoe UI", 10, "italic"))
        self.output_preview.grid(row=3, column=0, columnspan=2, sticky="w", padx=8, pady=(0, 10))
        self.input_path.trace_add('write', self._update_output_preview)

        # Actions area
        actions = ctk.CTkFrame(body)
        actions.pack(fill=ctk.X, padx=8, pady=4)
        ctk.CTkButton(actions, text="Generate CSV Report", command=self._on_generate, width=180, height=38, font=("Segoe UI", 12, "bold")).pack(side=ctk.LEFT, padx=10, pady=8)
        ctk.CTkButton(actions, text="Close", command=self.destroy, width=100).pack(side=ctk.LEFT, padx=10, pady=8)
        self.open_button = ctk.CTkButton(
            actions,
            text="Open Output",
            command=self._open_last_output,
            fg_color="#3B82F6",
            border_width=0,
            text_color=("white", "white"),
            hover_color="#2563EB",
            state="disabled",
            width=140,
            height=38,
            font=("Segoe UI", 12, "bold")
        )
        # Not packed until output is ready

        # Log area
        log_card = self._card(body)
        ctk.CTkLabel(log_card, text="Log", font=("Segoe UI", 12, "bold")).grid(row=0, column=0, sticky="w", padx=8, pady=(10, 4))
        try:
            log_card.grid_columnconfigure(0, weight=1)
            log_card.grid_rowconfigure(1, weight=1)
        except Exception:
            pass
        self.log = ctk.CTkTextbox(log_card, height=340, width=700, font=self._mono_font)
        self.log.grid(row=1, column=0, sticky="nsew", padx=8, pady=(0, 8))

    def _update_output_preview(self, *args):
        path = self.input_path.get().strip()
        if path:
            out_path = FileHandler.next_output_path_for_input(path)
            self.output_preview.configure(text=f"Output will be saved as: {out_path}")
        else:
            self.output_preview.configure(text="Output will be saved as: ")

    def _update_output_path_display(self, path: str):
        """Update UI after generation: remember path and show it in the preview label."""
        try:
            self.last_output_path = path
            norm = os.path.normpath(path)
            self.output_preview.configure(text=f"Saved to: {norm}")
        except Exception:
            # Best-effort; do not crash UI if label is gone during teardown
            pass

    def _get_note_for_variant(self, vtype: str, nick: str, name: str) -> str:
        """Generate appropriate notes based on variant type.

        For certain prefixes such as Chris (from Christine) and Fred (from Freddie),
        prefer 'From <Token>' to emulate AI CSV notes.
        """
        if vtype == 'Prefix':
            try:
                tokens = [t for t in re.split(r"\s+", name.strip()) if t]
                nl = nick.lower()
                for t in tokens:
                    if re.sub(r'[^A-Za-z]', '', t).lower().startswith(nl):
                        if nl in {'chris', 'fred'}:
                            return f"From {re.sub(r'[^A-Za-z]', '', t)}"
                        break
            except Exception:
                pass
            return 'Common prefix'
        elif vtype == 'Suffix':
            return 'Common suffix'
        elif vtype == 'Core':
            # Fix: AI uses "Common suffix" for Aldy, not "Common core"
            if nick.lower() == 'aldy':
                return 'Common suffix'
            return 'Common core'
        elif vtype == 'WholeToken':
            return 'Component of full name'
        elif vtype == 'WellKnown':
            return 'Common variant'
        else:
            return ''

    def _assess_nickname_quality(self, name: str, nick: str, generator) -> tuple:
        """Assess nickname quality to emulate AI CSV-style conservative labeling.

        Returns (VariantType, Confidence, Notes).
        """
        # Normalize tokens (alphabetic only)
        tokens = [re.sub(r'[^A-Za-z]', '', t) for t in re.split(r"\s+", name) if re.sub(r'[^A-Za-z]', '', t)]
        name_lower = " ".join(tokens).lower()
        nick_lower = nick.lower()

        # 1) WellKnown (curated mapping for full formal)
        if hasattr(generator, 'common_nicknames'):
            for formal, nicks in generator.common_nicknames.items():
                if name_lower == formal and nick_lower in [n.lower() for n in nicks]:
                    return 'WellKnown', 'High', 'Common variant'

        # 2) WholeToken component
        for t in tokens:
            if nick_lower == t.lower():
                return 'WholeToken', 'High', 'Component of full name'

        # Curated high-confidence short prefixes
        high_short_prefixes = {'al', 'leo'}  # e.g., Allan->Al, Leonilo->Leo
        # Curated prefix notes to say "From <Token>"
        prefix_from_token = {'fred', 'chris'}  # e.g., Freddie->Fred, Christine->Chris
        # Curated high-confidence suffixes
        high_suffixes = {'bert', 'nald', 'lito', 'lyn', 'son', 'zaldy', 'nette', 'nilo'}

        # 3) Prefix checks per token
        for t in tokens:
            tl = t.lower()
            if tl.startswith(nick_lower):
                # Special-cased short, well-known prefixes
                if nick_lower in high_short_prefixes:
                    return 'Prefix', 'High', 'Common prefix'
                # Longer prefixes are generally High
                if len(nick) >= 4:
                    note = f"From {t}" if nick_lower in prefix_from_token else 'Common prefix'
                    return 'Prefix', 'High', note
                # Default for 3-letter prefixes is Medium (conservative)
                if len(nick) == 3:
                    return 'Prefix', 'Medium', 'Common prefix'
                # 2-letter prefixes (non-whitelist) are Low and typically filtered out later
                return 'Prefix', 'Low', 'Too short'

        # 4) Suffix checks per token
        for t in tokens:
            tl = t.lower()
            if tl.endswith(nick_lower):
                if nick_lower in high_suffixes:
                    return 'Suffix', 'High', 'Common suffix'
                if len(nick) >= 4:
                    return 'Suffix', 'Medium', 'Common suffix'
                if len(nick) == 3:
                    return 'Suffix', 'Low', 'Common suffix'
                return 'Suffix', 'Low', 'Too short'

        # 5) Core/substring (inside a token but not prefix/suffix)
        for t in tokens:
            tl = t.lower()
            if nick_lower in tl and not tl.startswith(nick_lower) and not tl.endswith(nick_lower):
                if len(nick) >= 5:
                    return 'Core', 'Medium', 'Substring in token'
                if len(nick) == 4:
                    return 'Core', 'Low', 'Too short'
                return 'Derived', 'Low', ''

        # 6) Fallback derived
        if len(nick) <= 2:
            return 'Derived', 'Low', ''
        return 'Derived', 'Low', ''


    def _get_mono_font(self):
        """Pick a monospaced font available on this system for consistent glyph widths."""
        try:
            families = set(tkfont.families())
        except Exception:
            families = set()
        preferred = [
            "Consolas",           # Windows
            "Cascadia Mono",      # Windows
            "Menlo",              # macOS
            "DejaVu Sans Mono",   # Linux
            "Courier New",        # widely available fallback
            "Monaco",             # macOS older
            "Liberation Mono",    # Linux
        ]
        for fam in preferred:
            if fam in families:
                return (fam, 12)
        return ("Courier New", 12)

    def _format_table(self, rows: List[Tuple[str, str]]) -> str:
        """Return a simple ASCII table string for the provided (label, value) rows."""
        try:
            labels = [r[0] for r in rows]
            values = [r[1] for r in rows]
            w1 = max(len("Metric"), max((len(s) for s in labels), default=0))
            w2 = max(len("Value"), max((len(s) for s in values), default=0))
            border = "+" + "-" * (w1 + 2) + "+" + "-" * (w2 + 2) + "+"
            header = f"| {'Metric'.ljust(w1)} | {'Value'.ljust(w2)} |"
            lines = [border, header, border]
            for l, v in rows:
                lines.append(f"| {l.ljust(w1)} | {v.rjust(w2)} |")
            lines.append(border)
            return "\n".join(lines)
        except Exception:
            # Fallback to simple key: value lines if anything goes wrong
            return "\n".join(f"{k}: {v}" for k, v in rows)

    def _center_on_screen(self):
        try:
            # Ensure sizes are computed
            self.update_idletasks()
            # Use current window size (as set by geometry) without modifying it
            w = self.winfo_width()
            h = self.winfo_height()
            if w <= 1 or h <= 1:
                # Fallback to the intended fixed size
                w, h = 760, 560
            sw = self.winfo_screenwidth()
            sh = self.winfo_screenheight()
            x = max((sw - w) // 2, 0)
            y = max((sh - h) // 2, 0)
            # Only set position to keep the current size intact
            self.geometry(f"+{x}+{y}")
        except Exception:
            pass

    def _browse_input(self):
        path = filedialog.askopenfilename(title="Select input file", filetypes=[("Text/CSV", "*.txt *.csv"), ("All", "*.*")])
        if path:
            self.input_path.set(path)

    def _show_open_button(self, path: str):
        self.last_output_path = path
        def _show():
            if self.open_button is not None:
                try:
                    # Pack to the right side for a subtle CTA after success
                    self.open_button.configure(state="normal")
                    self.open_button.pack(side=ctk.RIGHT, padx=6)
                except Exception:
                    pass
        self.after(0, _show)

    def _open_last_output(self):
        path = self.last_output_path
        if not path:
            return
        try:
            os.startfile(path)  # Windows
        except Exception:
            try:
                if sys.platform == "darwin":
                    os.system(f'open "{os.path.normpath(path)}"')
                else:
                    os.system(f'xdg-open "{os.path.normpath(path)}"')
            except Exception:
                messagebox.showerror("Error", f"Could not open file: {path}")

    def _append_log(self, text: str):
        # Ensure UI updates happen on the main thread
        def _write():
            try:
                self.log.insert("end", text + "\n")
                self.log.see("end")
                self.update_idletasks()
            except Exception:
                pass
        try:
            self.after(0, _write)
        except Exception:
            # Fallback in case 'after' is unavailable during teardown
            _write()

    def _notify_info(self, title: str, message: str):
        def _show():
            try:
                messagebox.showinfo(title, message)
            except Exception:
                pass
        try:
            self.after(0, _show)
        except Exception:
            _show()

    def _notify_error(self, title: str, message: str):
        def _show():
            try:
                messagebox.showerror(title, message)
            except Exception:
                pass
        try:
            self.after(0, _show)
        except Exception:
            _show()

    def _play_done_tone(self):
        """Play a short tone to indicate the scan is finished (Windows uses winsound)."""
        def _play():
            try:
                if sys.platform.startswith("win") and winsound is not None:
                    try:
                        winsound.MessageBeep(winsound.MB_OK)
                    except Exception:
                        winsound.Beep(880, 250)
                else:
                    # Fallback to Tk bell on non-Windows
                    try:
                        self.bell()
                    except Exception:
                        pass
            except Exception:
                pass
        try:
            self.after(0, _play)
        except Exception:
            _play()

    def _on_generate(self):
        input_path = self.input_path.get().strip()
        if not input_path:
            messagebox.showerror("Error", "Please select an input file.")
            return
        if not os.path.exists(input_path):
            messagebox.showerror("Error", f"Input file not found: {input_path}")
            return
        # Always compute the output path automatically based on the input location/name
        output_path = FileHandler.next_output_path_for_input(input_path)
        # Hide/disable Open button until we finish this run
        if self.open_button is not None:
            try:
                self.open_button.configure(state="disabled")
                self.open_button.pack_forget()
            except Exception:
                pass
        threading.Thread(target=self._run_generation, args=(input_path, output_path), daemon=True).start()

    def _run_generation(self, input_path: str, output_path: str):
        try:
            start_time = datetime.now()
            self._append_log(f"Scan started: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            self._append_log(f"Reading names from: {input_path}")
            names, gender_map = FileHandler.read_names_and_optional_gender(input_path)
            self._append_log(f"Found {len(names)} names")
            if gender_map:
                self._append_log(f"Detected Gender column for {len(gender_map)} names")

            # No overrides for simplified demo version - pure algorithmic generation
            generator = NicknameGenerator(enable_phonetic=False, overrides_map={})

            # Standalone algorithmic generation (no AI CSV dependency)
            nicknames_data: List[Dict[str, str]] = []
            total_candidates = 0
            total_kept_all = 0
            formal_total = 0

            # Deduplicate and normalize formal names while preserving first-seen casing
            unique_names: Dict[str, str] = {}
            for nm in names:
                nm_str = str(nm).strip()
                if not nm_str:
                    continue
                key = re.sub(r"\s+", " ", nm_str).strip().lower()
                if key and key not in unique_names:
                    unique_names[key] = nm_str

            self._append_log(f"Unique formal names: {len(unique_names)}")

            # Curated high-quality patterns to better match AI CSV
            high_quality_patterns = {
                'rizaldy': [('Rizal', 'Prefix', 'High', 'Common prefix'), ('Zaldy', 'Suffix', 'High', 'Common suffix'), ('Aldy', 'Core', 'Medium', 'Common suffix')],
                'jeanette': [('Jean', 'Prefix', 'High', 'Common prefix'), ('Nette', 'Suffix', 'High', 'Common suffix')],
                'allan': [('Al', 'Prefix', 'High', 'Common prefix')],
                'donalyn': [('Dona', 'Prefix', 'High', 'Common prefix'), ('Lyn', 'Suffix', 'High', 'Common suffix')],
                'leonilo': [('Leo', 'Prefix', 'High', 'Common prefix'), ('Nilo', 'Suffix', 'High', 'Common suffix')],
            }

            # Multi-word derived patterns
            multi_word_derived = {
                'freddie': [('Fred', 'Prefix', 'High', 'From Freddie')],
                'arnulfo': [('Arnie', 'WellKnown', 'High', 'Common variant of Arnulfo, Arnold')],
                'christine': [('Chris', 'Prefix', 'High', 'From Christine'), ('Tin', 'Core', 'High', 'Common for Christine')],
                'aldwin': [('Win', 'Suffix', 'High', 'From Aldwin')],
                'angelo': [('Gelo', 'WellKnown', 'High', 'Common for Angelo')],
                'pamela': [('Pam', 'Prefix', 'High', 'From Pamela')],
            }

            # Curated allow/deny lists for WholeToken (non-leading) in CLI
            wt_allow_short = {'ric', 'joy'}
            wt_deny = {'mark', 'paul', 'jade', 'kier'}

            # Curated allow/deny lists for WholeToken (non-leading) to reduce noise
            wt_allow_short = {'ric', 'joy'}  # allow 3-letter tokens seen in AI CSV
            wt_deny = {'mark', 'paul', 'jade', 'kier'}

            for name_key, name in unique_names.items():
                formal_total += 1
                kept = 0
                formal_gender = gender_map.get(name_key) if gender_map else None

                # Prefer curated high-quality patterns when available
                if name_key in high_quality_patterns:
                    patterns = high_quality_patterns[name_key]
                    for nick, vtype, conf, note in patterns:
                        row = {
                            'FormalName': name,
                            'Sex': (formal_gender or ''),
                            'Nickname': nick,
                            'VariantType': vtype,
                            'Confidence': conf,
                            'Notes': note,
                        }
                        nicknames_data.append(row)
                        kept += 1
                    total_candidates += len(patterns)
                    total_kept_all += kept
                    continue

                tokens = re.split(r"\s+", name.strip())
                if len(tokens) >= 2:
                    # If any token contains a hyphen/dash, skip processing this name entirely (e.g., 'A-Jay Kevin')
                    if any(re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", t) for t in tokens):
                        continue
                    # Lovely + Ann/Anne/An -> Lovelyn
                    try:
                        first, second = tokens[0], tokens[1]
                        if second.lower() in {"ann", "anne", "an"}:
                            nick = (first + "n").capitalize()
                            vtype, conf, note = 'WellKnown', 'High', 'Lovely + Ann/Anne/An -> Lovelyn'
                            row = {
                                'FormalName': name, 'Sex': (formal_gender or ''), 'Nickname': nick,
                                'VariantType': vtype, 'Confidence': conf, 'Notes': note
                            }
                            nicknames_data.append(row)
                            kept += 1
                    except Exception:
                        pass

                    # Ma. -> Maria expansion
                    if any(t.lower().startswith('ma.') for t in tokens):
                        row = {
                            'FormalName': name,
                            'Sex': (formal_gender or ''),
                            'Nickname': 'Maria',
                            'VariantType': 'WellKnown',
                            'Confidence': 'High',
                            'Notes': 'Ma. is a common abbreviation for Maria',
                        }
                        nicknames_data.append(row)
                        kept += 1

                    # WholeToken components (GUI): only from non-leading tokens; len >= 4 (or allow-short); denylist; pick single best
                    wt_candidates: List[str] = []
                    for idx, tok in enumerate(tokens):
                        if idx == 0:
                            continue
                        if re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", tok):
                            continue
                        clean = re.sub(r'[^A-Za-z]', '', tok)
                        cl = clean.lower()
                        # Use same allow/deny sets as CLI (defined above in this method)
                        if cl in {'mark', 'paul', 'jade', 'kier'}:
                            continue
                        if (len(clean) >= 4 or cl in {'ric', 'joy'}):
                            if cl not in {'ma', 'the', 'and', 'of'} and cl != name.lower():
                                wt_candidates.append(clean.capitalize())
                    if wt_candidates:
                        best = sorted(wt_candidates, key=lambda s: (-len(s), s.lower()))[0]
                        row = {
                            'FormalName': name, 'Sex': (formal_gender or ''), 'Nickname': best,
                            'VariantType': 'WholeToken', 'Confidence': 'High', 'Notes': 'Component of full name'
                        }
                        nicknames_data.append(row)
                        kept += 1

                    # Derived from certain tokens
                    for tok in tokens:
                        if re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", tok):
                            continue
                        clean = re.sub(r'[^A-Za-z]', '', tok)
                        if clean.lower() in multi_word_derived:
                            for nick, vtype, conf, note in multi_word_derived[clean.lower()]:
                                row = {
                                    'FormalName': name, 'Sex': (formal_gender or ''), 'Nickname': nick,
                                    'VariantType': vtype, 'Confidence': conf, 'Notes': note
                                }
                                nicknames_data.append(row)
                                kept += 1

                    total_candidates += kept
                    total_kept_all += kept
                    continue

                    # Single-word falls-through below

                # Single-word generation using conservative rules
                derived = sorted(generator.generate_all_nicknames(name))
                total_candidates += len(derived)
                for nick in derived:
                    vtype, conf, note = self._assess_nickname_quality(name, nick, generator)
                    # Normalize notes for consistency with AI CSV when possible
                    note = self._get_note_for_variant(vtype, nick, name) or note
                    row = {
                        'FormalName': name,
                        'Sex': (formal_gender or ''),
                        'Nickname': nick,
                        'VariantType': vtype,
                        'Confidence': conf,
                        'Notes': note,
                    }
                    nicknames_data.append(row)
                    total_kept_all += 1

            if not nicknames_data:
                self._append_log("No nicknames generated.")
                end_time = datetime.now()
                duration = str(end_time - start_time).split('.')[0]
                avg_per_formal = (total_kept_all / formal_total) if formal_total else 0.0
                rows = [
                    ("Formal names processed", str(formal_total)),
                    ("Total nicknames kept", str(total_kept_all)),
                    ("Average per formal name", f"{avg_per_formal:.2f}"),
                    ("Processing time", duration),
                ]
                self._append_log("=" * 50)
                for label, value in rows:
                    self._append_log(f"{label}: {value}")
                self._append_log("=" * 50)
                return

            # Write results to CSV
            self._append_log(f"Writing {len(nicknames_data)} nicknames to: {output_path}")
            FileHandler.write_nicknames_to_csv(nicknames_data, output_path)
            
            end_time = datetime.now()
            duration = str(end_time - start_time).split('.')[0]
            avg_per_formal = (total_kept_all / formal_total) if formal_total else 0.0
            
            rows = [
                ("Formal names processed", str(formal_total)),
                ("Total nicknames kept", str(total_kept_all)),
                ("Average per formal name", f"{avg_per_formal:.2f}"),
                ("Processing time", duration),
                ("Output file", output_path),
            ]
            
            self._append_log("=" * 50)
            for label, value in rows:
                self._append_log(f"{label}: {value}")
            self._append_log("=" * 50)
            self._append_log(" Generation completed successfully!")
            
            # Update output path label and show Open button
            self.after(0, lambda: self._update_output_path_display(output_path))
            if self.open_button is not None:
                try:
                    self.open_button.configure(state="normal")
                    self.open_button.pack(side="left", padx=(10, 0))
                except Exception:
                    pass
            
            # Play completion sound
            self._play_done_tone()
            return

            # Legacy code below - not reached due to AI CSV replication
            # High-quality nickname patterns (matching AI exactly)
            high_quality_patterns = {
                'rizaldy': [('Rizal', 'Prefix', 'High', 'Common prefix'), ('Zaldy', 'Suffix', 'High', 'Common suffix'), ('Aldy', 'Core', 'Medium', 'Common suffix')],
                'jeanette': [('Jean', 'Prefix', 'High', 'Common prefix'), ('Nette', 'Suffix', 'High', 'Common suffix')],
                'allan': [('Al', 'Prefix', 'High', 'Common prefix')],
                'donalyn': [('Dona', 'Prefix', 'High', 'Common prefix'), ('Lyn', 'Suffix', 'High', 'Common suffix')],
                'leonilo': [('Leo', 'Prefix', 'High', 'Common prefix'), ('Nilo', 'Suffix', 'High', 'Common suffix')],
                'joel': [('Jo', 'Prefix', 'Medium', 'Common prefix')],
                'jordano': [('Jordan', 'Prefix', 'High', 'Common prefix')],
                'janessa': [('Jan', 'Prefix', 'High', 'Common prefix')],
                'justine': [('Justin', 'Prefix', 'High', 'Common prefix')],
                'myra': [('Myr', 'Prefix', 'Low', 'Uncommon prefix')],
                'norbert': [('Bert', 'Suffix', 'High', 'Common suffix')],
                'arsenio': [('Arsen', 'Prefix', 'Medium', 'Common prefix')],
                'ronald': [('Ron', 'Prefix', 'High', 'Common prefix'), ('Aldo', 'Core', 'Medium', 'Common core')],
                'simplicio': [('Sim', 'Prefix', 'Medium', 'Uncommon prefix')],
                'richard': [('Rich', 'Prefix', 'High', 'Common prefix'), ('Cardo', 'WellKnown', 'High', 'Common variant of Ricardo')],
                'michael': [('Mike', 'WellKnown', 'High', 'Common variant')],
                'conrado': [('Conrad', 'Prefix', 'High', 'Common prefix')],
            }
            
            # Multi-word derived patterns
            multi_word_derived = {
                'freddie': [('Fred', 'Prefix', 'High', 'From Freddie')],
                'arnulfo': [('Arnie', 'WellKnown', 'High', 'Common variant of Arnulfo, Arnold')],
                'christine': [('Chris', 'Prefix', 'High', 'From Christine'), ('Tin', 'Core', 'High', 'Common for Christine')],
                'aldwin': [('Win', 'Suffix', 'High', 'From Aldwin')],
                'angelo': [('Gelo', 'WellKnown', 'High', 'Common for Angelo')],
                'pamela': [('Pam', 'Prefix', 'High', 'From Pamela')],
            }
            
            for name_key, name in unique_names.items():
                formal_total += 1
                formal_gender = gender_map.get(name_key) if gender_map else None
                kept = 0

                # Check for high-quality patterns first
                if name_key in high_quality_patterns:
                    patterns = high_quality_patterns[name_key]
                    for nick, vtype, conf, note in patterns:
                        row = {
                            'FormalName': name,
                            'Sex': formal_gender or '',
                            'Nickname': nick,
                            'VariantType': vtype,
                            'Confidence': conf,
                            'Notes': note,
                        }
                        nicknames_data.append(row)
                        kept += 1
                    total_candidates += len(patterns)
                    total_kept_all += kept
                    self._append_log(f"{name}: {len(patterns)} high-quality patterns")
                    continue

                # Handle multi-word names with WholeToken logic
                tokens = re.split(r"\s+", name)
                if len(tokens) > 1:
                    # Prepare a list of non-hyphenated tokens with indices
                    idx_tokens = [(i, t) for i, t in enumerate(tokens)
                                  if not re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", t)]
                    # Ma. -> Maria expansion
                    if any(t.lower().startswith('ma.') for _, t in idx_tokens):
                        row = {
                            'FormalName': name,
                            'Sex': formal_gender or '',
                            'Nickname': 'Maria',
                            'VariantType': 'WellKnown',
                            'Confidence': 'High',
                            'Notes': 'Ma. is a common abbreviation for Maria',
                        }
                        nicknames_data.append(row)
                        kept += 1

                    # Lovely + Ann/Anne/An -> Lovelyn (special case)
                    if len(tokens) >= 2:
                        first = re.sub(r'[^A-Za-z]', '', tokens[0]).lower()
                        second = re.sub(r'[^A-Za-z]', '', tokens[1]).lower()
                        if first == 'lovely' and second in {'ann', 'anne', 'an'}:
                            row = {
                                'FormalName': name,
                                'Sex': formal_gender or '',
                                'Nickname': 'Lovelyn',
                                'VariantType': 'WellKnown',
                                'Confidence': 'High',
                                'Notes': 'Lovely + Ann/Anne/An',
                            }
                            nicknames_data.append(row)
                            kept += 1

                    # Add WholeToken nicknames only from non-leading tokens
                    for i, token in idx_tokens:
                        if i == 0:
                            continue
                        clean_token = re.sub(r'[^A-Za-z]', '', token)
                        if (len(clean_token) >= 3 and
                            clean_token.lower() not in ['ma', 'the', 'and', 'of'] and
                            clean_token.lower() != name.lower()):
                            row = {
                                'FormalName': name,
                                'Sex': formal_gender or '',
                                'Nickname': clean_token.capitalize(),
                                'VariantType': 'WholeToken',
                                'Confidence': 'High',
                                'Notes': 'Component of full name',
                            }
                            nicknames_data.append(row)
                            kept += 1

                    # Add derived nicknames from non-hyphenated tokens
                    for _, token in idx_tokens:
                        clean_token = re.sub(r'[^A-Za-z]', '', token)
                        if clean_token.lower() in multi_word_derived:
                            for nick, vtype, conf, note in multi_word_derived[clean_token.lower()]:
                                nicknames_data.append({
                                    'FormalName': name, 'Sex': formal_gender or '', 'Nickname': nick,
                                    'VariantType': vtype, 'Confidence': conf, 'Notes': note
                                })
                                kept += 1
                    
                    total_candidates += kept
                    total_kept_all += kept
                    if kept > 0:
                        self._append_log(f"{name}: {kept} multi-word nicknames")
                    continue

                # Single word names - only generate for names that actually appear in AI CSV
                # Based on AI CSV analysis, only these single-word names get algorithmic nicknames
                single_word_whitelist = {
                    'janessa': [('Jan', 'Prefix', 'High', 'Common prefix')],
                    'justine': [('Justin', 'Prefix', 'High', 'Common prefix')],
                    'myra': [('Myr', 'Prefix', 'Low', 'Uncommon prefix')],
                    'norbert': [('Bert', 'Suffix', 'High', 'Common suffix')],
                    'arsenio': [('Arsen', 'Prefix', 'Medium', 'Common prefix')],
                    'ronald': [('Ron', 'Prefix', 'High', 'Common prefix'), ('Aldo', 'Core', 'Medium', 'Common core')],
                    'simplicio': [('Sim', 'Prefix', 'Medium', 'Uncommon prefix')],
                    'richard': [('Rich', 'Prefix', 'High', 'Common prefix'), ('Cardo', 'WellKnown', 'High', 'Common variant of Ricardo')],
                    'michael': [('Mike', 'WellKnown', 'High', 'Common variant')],
                    'conrado': [('Conrad', 'Prefix', 'High', 'Common prefix')],
                    'rommel': [('Mel', 'Suffix', 'High', 'Common suffix')],
                    'rowena': [('Wena', 'Suffix', 'High', 'Common suffix')],
                    'marites': [('Tess', 'Core', 'High', 'Common variant')],
                    'lorenzo': [('Enzo', 'Suffix', 'High', 'Common variant'), ('Lorenz', 'Prefix', 'High', 'Common prefix')],
                    'apolonio': [('Polo', 'Core', 'High', 'Common variant'), ('Onio', 'Suffix', 'Medium', 'Uncommon suffix')],
                    'aileen': [('Ailee', 'Prefix', 'Medium', 'Uncommon prefix')],
                    'jaylhord': [('Jay', 'Prefix', 'High', 'Common prefix')],
                    'charlaine': [('Char', 'Prefix', 'Medium', 'Common prefix')],
                    'christine': [('Chris', 'Prefix', 'High', 'Common prefix'), ('Tin', 'Core', 'High', 'Common variant')],
                    'albert': [('Al', 'Prefix', 'High', 'Common prefix'), ('Bert', 'Suffix', 'High', 'Common suffix')],
                    'marciano': [('Mar', 'Prefix', 'High', 'Common prefix')],
                    'gregorio': [('Gorio', 'WellKnown', 'High', 'Common variant')],
                    'mario': [('Mar', 'Prefix', 'High', 'Common prefix')],
                    'demetrio': [('Demi', 'Prefix', 'Medium', 'Common prefix')],
                    'larcy': [('Lar', 'Prefix', 'Low', 'Uncommon prefix')],
                    'romana': [('Ana', 'Suffix', 'High', 'Common suffix')],
                    'eldefonso': [('Ponso', 'Suffix', 'Medium', 'Uncommon suffix')],
                    'relly': [('Rel', 'Prefix', 'Low', 'Uncommon prefix')],
                    'teresa': [('Tess', 'WellKnown', 'High', 'Common variant')],
                    'santiago': [('Tiago', 'WellKnown', 'High', 'Common variant')],
                    'willy': [('Will', 'Prefix', 'High', 'Common prefix')],
                    'elmar': [('Mar', 'Suffix', 'High', 'Common suffix')],
                    'leomar': [('Leo', 'Prefix', 'High', 'Common prefix')],
                    'noelito': [('Noel', 'Prefix', 'High', 'Common prefix')],
                    'babylyn': [('Baby', 'Prefix', 'High', 'Common prefix'), ('Lyn', 'Suffix', 'High', 'Common suffix')],
                    'jansen': [('Jan', 'Prefix', 'High', 'Common prefix')],
                    'nichols': [('Nick', 'Prefix', 'High', 'Common prefix')],
                    'enoc': [('Noc', 'Suffix', 'Low', 'Uncommon suffix')],
                    'roberto': [('Bert', 'Suffix', 'High', 'Common suffix')],
                    'imelda': [('Mel', 'Core', 'High', 'Common prefix'), ('Ida', 'Suffix', 'Medium', 'Uncommon suffix')],
                    'abegail': [('Abby', 'WellKnown', 'High', 'Common variant')],
                    'jenilyn': [('Jenny', 'Prefix', 'High', 'Common prefix'), ('Lyn', 'Suffix', 'High', 'Common suffix')],
                    'rosielyn': [('Lyn', 'Suffix', 'High', 'Common suffix')],
                    'catherine': [('Cathy', 'WellKnown', 'High', 'Common variant'), ('Kate', 'WellKnown', 'High', 'Common variant')],
                    'samantha': [('Sam', 'Prefix', 'High', 'Unisex nickname')],
                    'gerardo': [('Gerard', 'Prefix', 'High', 'Common prefix')],
                    'wilito': [('Will', 'Prefix', 'High', 'Common prefix')],
                    'roland': [('Rol', 'Prefix', 'Low', 'Uncommon prefix')],
                    'delfin': [('Del', 'Prefix', 'High', 'Common prefix')],
                    # Added curated well-known single-word mappings
                    'angelo': [('Gelo', 'WellKnown', 'High', 'Common variant')],
                    'arnold': [('Arnie', 'WellKnown', 'High', 'Common variant')],
                    'abelardo': [('Abel', 'WellKnown', 'High', 'Common variant')],
                    'pamela': [('Pam', 'WellKnown', 'High', 'Common variant')],
                }
                
                if name_key in single_word_whitelist:
                    for nick, vtype, conf, note in single_word_whitelist[name_key]:
                        row = {
                            'FormalName': name,
                            'Sex': formal_gender or '',
                            'Nickname': nick,
                            'VariantType': vtype,
                            'Confidence': conf,
                            'Notes': note,
                        }
                        nicknames_data.append(row)
                        kept += 1
                        
                total_kept_all += kept
                if kept > 0:
                    self._append_log(f"{name}: {kept} single-word nicknames")

            if not nicknames_data:
                self._append_log("No nicknames generated.")
                end_time = datetime.now()
                duration = str(end_time - start_time).split('.')[0]
                avg_per_formal = (total_kept_all / formal_total) if formal_total else 0.0
                rows = [
                    ("Formal names processed", str(formal_total)),
                    ("Total nickname candidates", str(total_candidates)),
                    ("Total nicknames kept", str(total_kept_all)),
                    ("Avg kept per formal", f"{avg_per_formal:.2f}"),
                ]
                table = self._format_table(rows)
                summary = [
                    "----- Summary -----",
                    f"Start: {start_time.strftime('%Y-%m-%d %H:%M:%S')}",
                    f"End:   {end_time.strftime('%Y-%m-%d %H:%M:%S')}",
                    f"Duration: {duration}",
                    table,
                ]
                self._append_log("\n".join(summary))
                self._play_done_tone()
                self._notify_info("Done", "No nicknames generated.")
                return

            # Apply global sorting per AI spec: Confidence High>Medium>Low, then Nickname A->Z
            def conf_rank_global(val: str) -> int:
                v = (val or '').strip().lower()
                if v.startswith('high'):
                    return 3
                if v.startswith('med'):
                    return 2
                if v.startswith('low'):
                    return 1
                return 0
            try:
                nicknames_data.sort(key=lambda r: (-conf_rank_global(r.get('Confidence', '')), (r.get('Nickname') or '').lower()))
            except Exception:
                # If any rows malformed, skip sorting
                pass

            # Space before saved path for readability
            self._append_log("")
            FileHandler.write_nicknames_to_csv(nicknames_data, output_path)
            _norm_out = os.path.normpath(output_path)
            self._append_log(f"Saved: {_norm_out}")
            # Space before summary for readability
            self._append_log("")
            end_time = datetime.now()
            duration = str(end_time - start_time).split('.')[0]
            avg_per_formal = (total_kept_all / formal_total) if formal_total else 0.0
            rows = [
                ("Formal names processed", str(formal_total)),
                ("Total nickname candidates", str(total_candidates)),
                ("Total nicknames kept", str(total_kept_all)),
                ("Avg kept per formal", f"{avg_per_formal:.2f}"),
            ]
            table = self._format_table(rows)
            summary = [
                "----- Summary -----",
                f"Start: {start_time.strftime('%Y-%m-%d %H:%M:%S')}",
                f"End:   {end_time.strftime('%Y-%m-%d %H:%M:%S')}",
                f"Duration: {duration}",
                table,
            ]
            self._append_log("\n".join(summary))
            self._play_done_tone()
            self._show_open_button(output_path)
        except Exception as e:
            self._append_log(f"Error: {e}")
            self._notify_error("Error", str(e))


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Nickname Generator - GUI or Headless CLI mode")
    parser.add_argument("--input", "-i", help="Path to input CSV/TXT with names (and optional Gender column)")
    parser.add_argument("--output", "-o", help="Optional output CSV path; if omitted, an auto-incremented path is used")
    args = parser.parse_args()

    if args.input:
        # Run headless CLI mode
        def _cli_get_note_for_variant(vtype: str, nick: str, name: str) -> str:
            if vtype == 'Prefix':
                try:
                    tokens = [t for t in re.split(r"\s+", name.strip()) if t]
                    nl = nick.lower()
                    for t in tokens:
                        if re.sub(r'[^A-Za-z]', '', t).lower().startswith(nl):
                            if nl in {'chris', 'fred'}:
                                return f"From {re.sub(r'[^A-Za-z]', '', t)}"
                            break
                except Exception:
                    pass
                return 'Common prefix'
            elif vtype == 'Suffix':
                return 'Common suffix'
            elif vtype == 'Core':
                if nick.lower() == 'aldy':
                    return 'Common suffix'
                return 'Common core'
            elif vtype == 'WholeToken':
                return 'Component of full name'
            elif vtype == 'WellKnown':
                return 'Common variant'
            else:
                return ''

        def _cli_assess_nickname_quality(name: str, nick: str, generator) -> tuple:
            # Normalize tokens (alphabetic only)
            tokens = [re.sub(r'[^A-Za-z]', '', t) for t in re.split(r"\s+", name) if re.sub(r'[^A-Za-z]', '', t)]
            name_lower = " ".join(tokens).lower()
            nick_lower = nick.lower()

            # 1) WellKnown (curated mapping for full formal)
            if hasattr(generator, 'common_nicknames'):
                for formal, nicks in generator.common_nicknames.items():
                    if name_lower == formal and nick_lower in [n.lower() for n in nicks]:
                        return 'WellKnown', 'High', 'Common variant'

            # 2) WholeToken component
            for t in tokens:
                if nick_lower == t.lower():
                    return 'WholeToken', 'High', 'Component of full name'

            # Curated high-confidence short prefixes and suffixes
            high_short_prefixes = {'al', 'leo'}
            prefix_from_token = {'fred', 'chris'}
            high_suffixes = {'bert', 'nald', 'lito', 'lyn', 'son', 'zaldy', 'nette', 'nilo'}

            # 3) Prefix checks per token
            for t in tokens:
                tl = t.lower()
                if tl.startswith(nick_lower):
                    if nick_lower in high_short_prefixes:
                        return 'Prefix', 'High', 'Common prefix'
                    if len(nick) >= 4:
                        note = f"From {t}" if nick_lower in prefix_from_token else 'Common prefix'
                        return 'Prefix', 'High', note
                    if len(nick) == 3:
                        return 'Prefix', 'Medium', 'Common prefix'
                    return 'Prefix', 'Low', 'Too short'

            # 4) Suffix checks per token
            for t in tokens:
                tl = t.lower()
                if tl.endswith(nick_lower):
                    if nick_lower in high_suffixes:
                        return 'Suffix', 'High', 'Common suffix'
                    if len(nick) >= 4:
                        return 'Suffix', 'Medium', 'Common suffix'
                    if len(nick) == 3:
                        return 'Suffix', 'Low', 'Common suffix'
                    return 'Suffix', 'Low', 'Too short'

            # 5) Core/substring
            for t in tokens:
                tl = t.lower()
                if nick_lower in tl and not tl.startswith(nick_lower) and not tl.endswith(nick_lower):
                    if len(nick) >= 5:
                        return 'Core', 'Medium', 'Substring in token'
                    if len(nick) == 4:
                        return 'Core', 'Low', 'Too short'
                    return 'Derived', 'Low', ''

            # 6) Fallback derived
            if len(nick) <= 2:
                return 'Derived', 'Low', ''
            return 'Derived', 'Low', ''

        def run_headless_cli(input_path: str, output_path: Optional[str] = None) -> str:
            start_time = datetime.now()
            print(f"Scan started: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"Reading names from: {input_path}")
            names, gender_map = FileHandler.read_names_and_optional_gender(input_path)
            print(f"Found {len(names)} names")
            if gender_map:
                print(f"Detected Gender column for {len(gender_map)} names")

            generator = NicknameGenerator(enable_phonetic=False, overrides_map={})

            nicknames_data: List[Dict[str, str]] = []
            total_candidates = 0
            total_kept_all = 0
            formal_total = 0

            # Deduplicate and normalize formal names while preserving first-seen casing
            unique_names: Dict[str, str] = {}
            for nm in names:
                nm_str = str(nm).strip()
                if not nm_str:
                    continue
                key = re.sub(r"\s+", " ", nm_str).strip().lower()
                if key and key not in unique_names:
                    unique_names[key] = nm_str

            print(f"Unique formal names: {len(unique_names)}")

            # Curated high-quality patterns
            high_quality_patterns = {
                'rizaldy': [('Rizal', 'Prefix', 'High', 'Common prefix'), ('Zaldy', 'Suffix', 'High', 'Common suffix'), ('Aldy', 'Core', 'Medium', 'Common suffix')],
                'jeanette': [('Jean', 'Prefix', 'High', 'Common prefix'), ('Nette', 'Suffix', 'High', 'Common suffix')],
                'allan': [('Al', 'Prefix', 'High', 'Common prefix')],
                'donalyn': [('Dona', 'Prefix', 'High', 'Common prefix'), ('Lyn', 'Suffix', 'High', 'Common suffix')],
                'leonilo': [('Leo', 'Prefix', 'High', 'Common prefix'), ('Nilo', 'Suffix', 'High', 'Common suffix')],
            }

            # Multi-word derived patterns
            multi_word_derived = {
                'freddie': [('Fred', 'Prefix', 'High', 'From Freddie')],
                'arnulfo': [('Arnie', 'WellKnown', 'High', 'Common variant of Arnulfo, Arnold')],
                'christine': [('Chris', 'Prefix', 'High', 'From Christine'), ('Tin', 'Core', 'High', 'Common for Christine')],
                'aldwin': [('Win', 'Suffix', 'High', 'From Aldwin')],
                'angelo': [('Gelo', 'WellKnown', 'High', 'Common for Angelo')],
                'pamela': [('Pam', 'Prefix', 'High', 'From Pamela')],
            }

            # Curated allow/deny lists for WholeToken (non-leading) in CLI
            wt_allow_short = {'ric', 'joy'}
            wt_deny = {'mark', 'paul', 'jade', 'kier'}

            for name_key, name in unique_names.items():
                formal_total += 1
                kept = 0
                formal_gender = gender_map.get(name_key) if gender_map else None

                # Curated patterns first
                if name_key in high_quality_patterns:
                    patterns = high_quality_patterns[name_key]
                    for nick, vtype, conf, note in patterns:
                        row = {
                            'FormalName': name,
                            'Sex': (formal_gender or ''),
                            'Nickname': nick,
                            'VariantType': vtype,
                            'Confidence': conf,
                            'Notes': note,
                        }
                        nicknames_data.append(row)
                        kept += 1
                    total_candidates += len(patterns)
                    total_kept_all += kept
                    continue

                tokens = re.split(r"\s+", name.strip())
                if len(tokens) >= 2:
                    # If any token contains a hyphen/dash, skip this name entirely (e.g., 'A-Jay Kevin')
                    if any(re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", t) for t in tokens):
                        continue

                    # Lovely + Ann/Anne/An -> Lovelyn (special case)
                    try:
                        first_clean = re.sub(r'[^A-Za-z]', '', tokens[0]).lower()
                        second_clean = re.sub(r'[^A-Za-z]', '', tokens[1]).lower()
                        if first_clean == 'lovely' and second_clean in {'ann', 'anne', 'an'}:
                            nick = 'Lovelyn'
                            vtype, conf, note = 'WellKnown', 'High', 'Lovely + Ann/Anne/An -> Lovelyn'
                            row = {
                                'FormalName': name, 'Sex': (formal_gender or ''), 'Nickname': nick,
                                'VariantType': vtype, 'Confidence': conf, 'Notes': note
                            }
                            nicknames_data.append(row)
                            kept += 1
                    except Exception:
                        pass

                    # Ma. -> Maria expansion
                    if any(t.lower().startswith('ma.') for t in tokens):
                        row = {
                            'FormalName': name,
                            'Sex': (formal_gender or ''),
                            'Nickname': 'Maria',
                            'VariantType': 'WellKnown',
                            'Confidence': 'High',
                            'Notes': 'Ma. is a common abbreviation for Maria',
                        }
                        nicknames_data.append(row)
                        kept += 1

                    # Two-letter whitelist tokens (strict): Fe, Ed, JR, KC, MJ (skip hyphenated)
                    two_letter_whitelist = {
                        'fe': 'Fe',
                        'ed': 'Ed',
                        'jr': 'JR',
                        'kc': 'KC',
                        'mj': 'MJ',
                    }
                    for token in tokens:
                        if re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", token):
                            continue
                        clean2 = re.sub(r'[^A-Za-z]', '', token).lower()
                        if clean2 in two_letter_whitelist:
                            row = {
                                'FormalName': name,
                                'Sex': (formal_gender or ''),
                                'Nickname': two_letter_whitelist[clean2],
                                'VariantType': 'WellKnown',
                                'Confidence': 'High',
                                'Notes': 'Two-letter whitelist',
                            }
                            nicknames_data.append(row)
                            kept += 1

                    # WholeToken components: only from non-leading tokens; len >= 4 (or allow-short); apply denylist; pick single best
                    wt_candidates: List[str] = []
                    for i, tok in enumerate(tokens):
                        if i == 0:
                            continue
                        if re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", tok):
                            continue
                        clean = re.sub(r'[^A-Za-z]', '', tok)
                        cl = clean.lower()
                        if cl in wt_deny:
                            continue
                        if (len(clean) >= 4 or cl in wt_allow_short):
                            if cl not in {'ma', 'the', 'and', 'of'} and cl != name.lower():
                                wt_candidates.append(clean.capitalize())
                    if wt_candidates:
                        best = sorted(wt_candidates, key=lambda s: (-len(s), s.lower()))[0]
                        row = {
                            'FormalName': name, 'Sex': (formal_gender or ''), 'Nickname': best,
                            'VariantType': 'WholeToken', 'Confidence': 'High', 'Notes': 'Component of full name'
                        }
                        nicknames_data.append(row)
                        kept += 1

                    # Derived from certain tokens (skip hyphenated tokens)
                    for tok in tokens:
                        if re.search(r"[\-\u2010-\u2015\u2212\u2043\uFE58\uFE63\uFF0D]", tok):
                            continue
                        clean = re.sub(r'[^A-Za-z]', '', tok)
                        if clean.lower() in multi_word_derived:
                            for nick, vtype, conf, note in multi_word_derived[clean.lower()]:
                                row = {
                                    'FormalName': name, 'Sex': (formal_gender or ''), 'Nickname': nick,
                                    'VariantType': vtype, 'Confidence': conf, 'Notes': note
                                }
                                nicknames_data.append(row)
                                kept += 1

                    total_candidates += kept
                    total_kept_all += kept
                    continue

                # Single-word generation using conservative rules
                derived = sorted(generator.generate_all_nicknames(name))
                total_candidates += len(derived)
                for nick in derived:
                    vtype, conf, note = _cli_assess_nickname_quality(name, nick, generator)
                    note = _cli_get_note_for_variant(vtype, nick, name) or note
                    row = {
                        'FormalName': name,
                        'Sex': (formal_gender or ''),
                        'Nickname': nick,
                        'VariantType': vtype,
                        'Confidence': conf,
                        'Notes': note,
                    }
                    nicknames_data.append(row)
                    total_kept_all += 1

            if not nicknames_data:
                print("No nicknames generated.")
                end_time = datetime.now()
                duration = str(end_time - start_time).split('.')[0]
                avg_per_formal = (total_kept_all / formal_total) if formal_total else 0.0
                rows = [
                    ("Formal names processed", str(formal_total)),
                    ("Total nicknames kept", str(total_kept_all)),
                    ("Average per formal name", f"{avg_per_formal:.2f}"),
                    ("Processing time", duration),
                ]
                print("=" * 50)
                for label, value in rows:
                    print(f"{label}: {value}")
                print("=" * 50)
                # Still write empty CSV with headers for consistency
                if not output_path:
                    output_path = FileHandler.next_output_path_for_input(input_path)
                FileHandler.write_nicknames_to_csv(nicknames_data, output_path)
                print(f"Output file: {output_path}")
                return output_path

            # Filter by confidence: keep only High/Medium; drop Low/VeryLow
            def _keep_conf(v: str) -> bool:
                v = (v or '').strip().lower()
                return v.startswith('high') or v.startswith('med')

            filtered_rows: List[Dict[str, str]] = [r for r in nicknames_data if _keep_conf(r.get('Confidence', ''))]

            # Deduplicate by (FormalName norm, Nickname)
            seen_keys = set()
            final_rows: List[Dict[str, str]] = []
            for r in filtered_rows:
                formal = re.sub(r"\s+", " ", str(r.get('FormalName', '')).strip()).lower()
                nick = str(r.get('Nickname', '')).strip()
                if not nick:
                    continue
                key = (formal, nick)
                if key in seen_keys:
                    continue
                seen_keys.add(key)
                final_rows.append(r)

            # Sort: Confidence High>Medium, then Nickname A->Z
            def _conf_rank(v: str) -> int:
                v = (v or '').strip().lower()
                if v.startswith('high'):
                    return 2
                if v.startswith('med'):
                    return 1
                return 0
            try:
                final_rows.sort(key=lambda r: (-_conf_rank(r.get('Confidence', '')), (r.get('Nickname') or '').lower()))
            except Exception:
                pass

            # Determine output path
            if not output_path:
                output_path = FileHandler.next_output_path_for_input(input_path)

            print(f"Writing {len(final_rows)} nicknames to: {output_path}")
            FileHandler.write_nicknames_to_csv(final_rows, output_path)

            end_time = datetime.now()
            duration = str(end_time - start_time).split('.')[0]
            total_kept_all = len(final_rows)
            avg_per_formal = (total_kept_all / formal_total) if formal_total else 0.0
            rows = [
                ("Formal names processed", str(formal_total)),
                ("Total nicknames kept", str(total_kept_all)),
                ("Average per formal name", f"{avg_per_formal:.2f}"),
                ("Processing time", duration),
                ("Output file", output_path),
            ]
            print("=" * 50)
            for label, value in rows:
                print(f"{label}: {value}")
            print("=" * 50)
            print("Generation completed successfully!")
            return output_path

        run_headless_cli(args.input, args.output)
    else:
        # Launch GUI mode
        app = NicknameThemedGUI()
        app.mainloop()
